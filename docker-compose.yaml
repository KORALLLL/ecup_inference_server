version: "3.9"

services:
  triton:
    image: nvcr.io/nvidia/tritonserver:${TRITON_IMAGE_TAG:-24.08-py3}
    command: ["tritonserver", "--model-repository=/models", "--log-verbose=1"]
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}
    ports:
      - "${TRITON_HTTP_PORT:-18000}:8000"   # HTTP
      - "${TRITON_GRPC_PORT:-18001}:8001"   # gRPC
      - "${TRITON_METRICS_PORT:-18002}:8002" # Prometheus
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    # Для локального репозитория раскомментируйте volumes и выставьте MODEL_REPOSITORY=/models в .env
    volumes:
      - ${TRITON_REPO_PATH}:/models:ro
